{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import pickle\n",
                "\n",
                "with open('models/model_config.pkl', 'rb') as f:\n",
                "    config = pickle.load(f)\n",
                "\n",
                "char2index = config['char2index']\n",
                "index2char = config['index2char']\n",
                "HIDDEN_SIZE = config['hidden_size']\n",
                "N_CHARS = config['n_chars']\n",
                "MAX_LENGTH = config['max_length']\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "class EncoderRNN(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
                "        super(EncoderRNN, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
                "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "\n",
                "    def forward(self, input):\n",
                "        embedded = self.dropout(self.embedding(input))\n",
                "        output, hidden = self.gru(embedded)\n",
                "        return output, hidden\n",
                "\n",
                "class DecoderRNN(nn.Module):\n",
                "    def __init__(self, hidden_size, output_size, dropout=0.1):\n",
                "        super(DecoderRNN, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
                "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
                "        self.out = nn.Linear(hidden_size, output_size)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "\n",
                "    def forward(self, input, hidden):\n",
                "        output = self.dropout(self.embedding(input))\n",
                "        # REMOVED ReLU to match training configuration\n",
                "        output, hidden = self.gru(output, hidden)\n",
                "        output = self.out(output)\n",
                "        return output, hidden\n",
                "\n",
                "class Seq2Seq(nn.Module):\n",
                "    def __init__(self, encoder, decoder, device):\n",
                "        super().__init__()\n",
                "        self.encoder = encoder\n",
                "        self.decoder = decoder\n",
                "        self.device = device\n",
                "\n",
                "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
                "        pass\n",
                "\n",
                "enc = EncoderRNN(N_CHARS, HIDDEN_SIZE).to(device)\n",
                "dec = DecoderRNN(HIDDEN_SIZE, N_CHARS).to(device)\n",
                "model = Seq2Seq(enc, dec, device).to(device)\n",
                "\n",
                "model.load_state_dict(torch.load('models/best_model.pt', map_location=device))\n",
                "model.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def correct_word(word: str, model_path: str = None) -> str:\n",
                "    indexes = []\n",
                "    for char in word:\n",
                "        if char in char2index:\n",
                "            indexes.append(char2index[char])\n",
                "            \n",
                "    indexes.append(1) # EOS\n",
                "    \n",
                "    # Padding is required because the model was trained with unmasked padded sequences\n",
                "    if len(indexes) < MAX_LENGTH:\n",
                "        indexes += [2] * (MAX_LENGTH - len(indexes))\n",
                "    else:\n",
                "        indexes = indexes[:MAX_LENGTH]\n",
                "        \n",
                "    tensor_in = torch.tensor(indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        _, hidden = model.encoder(tensor_in)\n",
                "        \n",
                "        # Use first char of input as seed (Workaround for training logic)\n",
                "        if len(indexes) > 0:\n",
                "             start_token = indexes[0]\n",
                "             decoded_chars = [index2char[start_token]]\n",
                "        else:\n",
                "             start_token = 0\n",
                "             decoded_chars = []\n",
                "             \n",
                "        decoder_input = torch.tensor([[start_token]], device=device)\n",
                "        \n",
                "        for _ in range(MAX_LENGTH):\n",
                "            output, hidden = model.decoder(decoder_input, hidden)\n",
                "            top1 = output.argmax(2)\n",
                "            token_idx = top1.item()\n",
                "            \n",
                "            if token_idx == 1: break\n",
                "            if token_idx == 2: break\n",
                "            \n",
                "            decoded_chars.append(index2char[token_idx])\n",
                "            decoder_input = top1\n",
                "            \n",
                "    return \"\".join(decoded_chars)\n",
                "\n",
                "test_words = [\n",
                "    \"გამარჰონა\",\n",
                "    \"თბილისი\",\n",
                "    \"პროგამა\",\n",
                "    \"საქარველო\",\n",
                "    \"უნივერსიტეტი\"\n",
                "]\n",
                "\n",
                "for tw in test_words:\n",
                "    print(f\"Input: {tw:15} -> Output: {correct_word(tw)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "demo_set = [\n",
                "    (\"შკოლა\", \"სკოლა\"),\n",
                "    (\"მასწავლბელი\", \"მასწავლებელი\"),\n",
                "    (\"ისტრია\", \"ისტორია\"),\n",
                "    (\"გეოგრფია\", \"გეოგრაფია\"),\n",
                "    (\"ლიტერატრა\", \"ლიტერატურა\"),\n",
                "    (\"ქალაქ\", \"ქალაქი\"),\n",
                "    (\"მანქან\", \"მანქანა\"),\n",
                "    (\"კომპიუტრი\", \"კომპიუტერი\"),\n",
                "    (\"ტელეფონი\", \"ტელეფონი\"),\n",
                "    (\"ინტერნტი\", \"ინტერნეტი\"),\n",
                "    (\"წიგნი\", \"წიგნი\"),\n",
                "    (\"რვეული\", \"რვეული\"),\n",
                "    (\"კალამი\", \"კალამი\"),\n",
                "    (\"დაფა\", \"დაფა\"),\n",
                "    (\"მაგია\", \"მაგიდა\"),\n",
                "    (\"სკამ\", \"სკამი\"),\n",
                "    (\"ფანჯრა\", \"ფანჯარა\"),\n",
                "    (\"კარი\", \"კარი\"),\n",
                "    (\"იატკი\", \"იატაკი\"),\n",
                "    (\"ჭერი\", \"ჭერი\")\n",
                "]\n",
                "\n",
                "for inp, target in demo_set:\n",
                "    pred = correct_word(inp)\n",
                "    status = \"✅\" if pred == target else f\"❌ (Expected {target})\"\n",
                "    print(f\"In: {inp:15} | Out: {pred:15} | {status}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}